<!DOCTYPE html>
<html>
<head>
<title>Rajat Shinde - PMRF Annual Review Webpage</title>
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.16.0/umd/popper.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>
<style type="text/css">
    
    a {
      color: #1772d0;
      text-decoration: none;
    }
    
    a:focus,
    a:hover {
      color: #f09228;
      text-decoration: none;
    }
    
    body,
    td,
    th,
    tr,
    p,
    i,
    a {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      text-align:justify;
    }
    
    b {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    
    heading {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 22px;
    }
    
    papertitle {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 700
    }
    
    name {
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
      font-size: 32px;
    }
    news {
      font-family: 'Calibri', Verdana, Helvetica, sans-serif;
      font-size: 16px;
    }
    

    table{
      font-family: 'Lato', Verdana, Helvetica, sans-serif;
        border-collapse: collapse;
  border-spacing: 0;
  border:2px solid #ffffff;
    }
    th{
  border:1px solid #ffffff;
    }
    td{
  border:1px solid #ffffff;
    }
    tr{
  border:1px solid #ffffff;
    }

    img {
  border-radius: 5%;
}

#myBeyondTopNav{
  margin: 1%;
}

body {
  margin: 0;
}
.myTopnavClass,
.topnav {
  overflow: hidden;
  background-color: #333;
  position: sticky;
  width: 100%;
  top: 0;
}
.topnav a {
  float: left;
  display: block;
  color: #f2f2f2;
  text-align: center;
  padding: 14px 16px;
  text-decoration: none;
  font-size: 17px;
}

.topnav a:hover {
  background-color: #ddd;
  color: black;
}

.topnav a.active {
  background-color: #f09228;
  color: white;
}

.topnav .icon {
  display: none;
}
.navbar{
padding: 0;
}

@media screen and (max-width: 600px) {
  .topnav a:not(:first-child) {display: none;}
  .topnav a.icon {
    float: right;
    display: block;
  }
}

@media screen and (max-width: 600px) {
  .topnav.responsive {position: relative;}
  .topnav.responsive .icon {
    position: absolute;
    right: 0;
    top: 0;
  }
  .topnav.responsive a {
    float: none;
    display: block;
    text-align: left;
  }
}
</style>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>
function myFunction() {
  var x = document.getElementById("myTopnav");
  if (x.className === "myTopnavClass navbar-collapse collapse") {
    x.className += " responsive";
  } else {
    x.className = "myTopnavClass navbar-collapse topnav collapse";
  }
}
</script>

<body>
  <nav class="topnav navbar navbar-expand-md navbar-dark" style="width:100%">
  <a href="#name" class="active" onclick="myFunction()">Home</a>
  <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#myTopnav">
    <span class="navbar-toggler-icon"></span>
  </button>
  <div class="myTopnavClass navbar-collapse collapse" id="myTopnav">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link" href="#acad" onclick="myFunction()">Academics</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#research" onclick="myFunction()">Research</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="#publications" onclick="myFunction()">Publications</a>
      </li> 
      <li class="nav-item">
        <a class="nav-link" href="#courses" onclick="myFunction()">Courses</a>
      </li>  
      <li class="nav-item">
        <a class="nav-link" href="#ta" onclick="myFunction()">Teaching Assistantship</a>
      </li>    
    </ul>
  </div>  
</nav>


<!-- <div class="topnav collapse show" id="myTopnav" data-toggle="collapse">
  <a href="#name" class="active">Home</a>
  <a href="#acad">Academics</a>
  <a href="#research">Research</a>
  <a href="#publications">Publications</a>
  <a href="#courses">Courses</a>
  <a href="#ta">Teaching Assistantship</a>
  <a href="javascript:void(0);" class="icon" onclick="myFunction()">
    <i class="fa fa-bars"></i>
  </a>
</div> -->

<div class="beyondTopNav" id="myBeyondTopNav">
<h2 id="name">Rajat Chandrashekhar Shinde</h2>
<div>
<table width="100%" align="center" border="0" cellspacing="" cellpadding="5px">
      <tr>
        <td width="80%" valign="middle">
          <p align="center">
          </p>
          <p>I am a Masters-PhD (Dual Degree) Student in Geo-informatics, and a <a href='https://pmrf.in/'>Prime Minister's Research Fellow </a>(2018) working under the supervision of <a href='https://www.csre.iitb.ac.in/~sdurbha'> Prof. Surya S Durbha </a> at the <a href='https://www.geosysiot.in'> Geocomputational Systems and IoT Group </a> in <a href='https://www.csre.iitb.ac.in'> Centre of Studies in Resources Engineering</a>, <a href='https://www.iitb.ac.in'> Indian Institute of Technology Bombay</a>. I have completed my undergraduation in Electronics and Telecommunication Engineering from <a href='https://www.nitrr.ac.in'> National Institute of Technology Raipur </a> in 2016.
          </p>
          <p>My research interests lie at the intersection of 3D computer vision, deep learning, sparse coding for 3D lidar data, and high performance computing. My Masters-PhD thesis involves application of deep learning for onboard lidar point cloud processing. <br/>
          </p>
        </td>
        <td width="20%">
          <center><img src="assets/images/me.jpg" style="width:auto;"></center>
            <p>
              <center>
                <a href="mailto:rajatshinde@iitb.ac.in">Email | </a>
                <a href="assets/docs/CV_RajatShinde.pdf">CV | </a>
                <a href="https://scholar.google.com/citations?hl=en&user=8T3fy5wAAAAJ">Scholar | </a>
                <a href="https://orcid.org/0000-0002-9505-6204">ORCID </a>
                <!-- <a href="https://www.osgeo.org/member/shinde/">OSGeo</a>
                <a href="https://www.linkedin.com/in/rajat-shinde/">LinkedIn | </a>
                <a href="https://www.twitter.com/shinde_rajat">Twitter | </a>
                <a href="https://github.com/omshinde">Github </a> -->
              </center>
            </p>
        </td>
      </tr>
</table>
</div>
<hr/>

<!-- <p>My research interests lie at the intersection of 3D computer vision, machine learning, embedded systems, Internet of Things, high performance computing and signal processing. My Masters-PhD topic involves application of Machine Learning for onboard point cloud processing. <br/>

<a href="mailto:rajatshinde@iitb.ac.in">Email | </a>
<a href="https://scholar.google.com/citations?hl=en&user=8T3fy5wAAAAJ">Scholar | </a>
<a href="https://orcid.org/0000-0002-9505-6204">ORCID | </a>
<a href="https://www.osgeo.org/member/shinde/">OSGeo | </a>
<a href="https://www.linkedin.com/in/rajat-shinde/">LinkedIn | </a>
<a href="https://www.twitter.com/shinde_rajat">Twitter | </a>
<a href="https://github.com/omshinde">Github </a>
</p> -->
<!-- <heading> News </heading>
<news><p>
  <ul>
    <li>
      [June 2020] 2 Papers selected as Oral Presentation at the IGARSS 2020 <i>(virtual conference)</i>
    </li>
    <li>
      [May 2020] Contributing as GSoC Organization Admin and Mentor for the OSGeo
    </li>
    <li>
      [September 2019] Took a session on <a href="https://docs.google.com/presentation/d/11vX84AscOWIQzRXqbA_xNc5eAtRkJXc0IlsWJnSrQd0/edit?usp=sharing">"Earth Engine UI & Web Apps"</a> at the Earth Engine India Student Summit 2019. Thanks to Google Earth Outreach team for organizing this event
    </li>
    <li>
      [August 2019] We successfully orgnanised a workshop on <a href="https://2019.foss4g.org/schedule/workshops/"> "Building Standards Compliant Geospatial Web Applications â€“ The Quick and Easy MapMint Way" </a> in FOSS4G 2019 conference held in Bucharest
    </li>
    <li>
      [August 2019] First trip to Japan. Attended and presented papers at the <a href="https://igarss2019.org/">IEEE Geoscience and Remote Sensing Symposium (IGARSS 2019) </a>held in Yokohama, Japan
    </li>
    <li>
      [August 2019] Successfully completed the project "EcoViz: A Google Earth Engine based web application for robust visualization of ecological status of selected world heritage sites of the Western Ghats in India" with <a href="https://www.ncf-india.org/">Nature Conservation Foundation</a> for the <a href="https://sites.google.com/view/summerofearthengine/mentees">Google Summer of Earth Engine Research Program</a>
    </li>
    <li>
      [August 2019] End of the Google Summer of Code 2019. It was a great experience mentoring 2 successful projects along with the MapMint team under the OSGeo organization 
    </li>
    <li>
      [July 2019] Webinar on "Hyperparameter Tuning in Google Earth Engine" at the <a href="https://youtu.be/CfPJb5iAsKg">Community on Air Webinar </a>organized by the Google Earth Engine India Community
    </li>
  </ul>
</p>
</news> -->


<div>
<heading id="acad">Academics</heading>
<!-- <table width="100%" align="center" border="0" cellspacing="" cellpadding="5px">
  <tr>
    <td width="50%" valign="middle">
      <b>M.Tech - Ph.D (Dual Degree) </b><br/>
      (2016 - Present) | <i>CPI: 9.57/10</i> <br/>
      Prime Minister's Research Fellow 2018 <br/>
      <a href="assets/images/SAIL-PM-Mtech.jpg">Prime Minister's Trophy Sarvottam Scholarship </a> granted by SAIL (2016-2018) <br/>
      Geoinformatics and Resources Engineering <br/>
      <a href="https://csre.iitb.ac.in">Centre of Studies in Resources Engineering <br/> </a>
      <a href="https://iitb.ac.in">Indian Institute of Technology Bombay, India <br/></a>
    </td>
    <td width="50%" valign="middle">
      <b>B.Tech </b><br/>
      (2012 - 2016) | <i>CPI: 8.94/10</i> <br/>
      <a href="assets/images/SAIL-PM-Btech.jpg">Prime Minister's Trophy Sarvottam Scholarship </a> granted by SAIL (2012-2016) <br/>
      Electronics and Telecommunication Engineering <br/>
      <a href="https://nitrr.ac.in">National Institute of Technology Raipur, India <br/></a>
      <a href="assets/docs/BTechThesis.pdf">Thesis</a>
    </td>
  </tr>
</table></div> <br /> -->

<ul>      
  <li><b>M.Tech - Ph.D (Dual Degree) </b><br/>
    (2016 - Present) | <i>CPI: 9.57/10</i> <br/>
    Prime Minister's Research Fellow 2018 <br/>
    <a href="assets/images/SAIL-PM-Mtech.jpg">Prime Minister's Trophy Sarvottam Scholarship </a> granted by SAIL (2016-2018) <br/>
    Geoinformatics and Resources Engineering <br/>
    <a href="https://csre.iitb.ac.in">Centre of Studies in Resources Engineering <br/> </a>
    <a href="https://iitb.ac.in">Indian Institute of Technology Bombay, India <br/></a>
  </li> <br/>
      
  <li><b>B.Tech </b><br/>
    (2012 - 2016) | <i>CPI: 8.94/10</i> <br/>
    <a href="assets/images/SAIL-PM-Btech.jpg">Prime Minister's Trophy Sarvottam Scholarship </a> granted by SAIL (2012-2016) <br/>
    Electronics and Telecommunication Engineering <br/>
    <a href="https://nitrr.ac.in">National Institute of Technology Raipur, India <br/></a>
    <a href="assets/docs/BTechThesis.pdf">Thesis</a>
  </li>
</ul>

<div style="margin: 10px;">
<heading id="research"> Research </heading>
<p>
  The research project primarily focuses on <b><i>onboard real-time lidar point cloud processing</i></b>. Lidar point cloud, unlike images, possesses 3D accurate information, is unstructured. It is widely used in surveying and mapping applications where the lidar sensor mounted on a spaceborne or airborne platform remotely acquires data. Over the years, there has been active research and development in lidar sensors, thus improving the accuracy of scanning at comparatively low manufacturing costs. This paradigm shift brings immense opportunities for implementing algorithms capable of real-time processing. Moreover, rapid development in portable, high-performance computing platforms consisting of GPUs, FPGA, and ASICS have unearthed the research potential and opened new dimensions for using lidar sensors and high-performance computing for industrial applications. The focus of the research project is to explore both aspects by developing an end-to-end product. 
</p>
<p>
  <b>The research contributions involve developing algorithms for 3D lidar point cloud processing onboard a hardware module and a software module for scientific visualization of the generated results. The project addresses various remote sensing research objectives such as urban modeling, forestry, and rapid disaster assessment and mitigation.</b>
</p>
</div>

<div>
<heading id="publications"> Publications </heading>
<table width="100%" align="center" border="0" cellspacing="" cellpadding="5px">
  <!-- Uncomment for Journals <tr>
    <td width="20%">
      <center><img src="assets/images/me.jpg" style="width:70%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Online Point Cloud Super Resolution Using Dictionary Learning For 3d Urban Perception</papertitle> <br/>
        Rajat Shinde, Abhishek Potnis, Surya Durbha <br/>
        <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020, virtual conference) </i> <br/>
      </p>  
    </td>
  </tr>

   <tr>
    <td width="20%">
      <center><img src="assets/images/me.jpg" style="width:70%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Online Point Cloud Super Resolution Using Dictionary Learning For 3d Urban Perception</papertitle> <br/>
        Rajat Shinde, Abhishek Potnis, Surya Durbha <br/>
        <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020, virtual conference) </i> <br/>
      </p>  
    </td>
  </tr>

  <tr>
    <td width="20%">
      <center><img src="assets/images/me.jpg" style="width:50%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Online Point Cloud Super Resolution Using Dictionary Learning For 3d Urban Perception</papertitle> <br/>
        Rajat Shinde, Abhishek Potnis, Surya Durbha <br/>
        <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020, virtual conference) </i> <br/>
      </p>  
    </td>
  </tr> -->

  <tr>
    <td width="20%">
      <center><img src="assets/images/olIgarss2020.gif" style="width:90%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Online Point Cloud Super Resolution Using Dictionary Learning For 3d Urban Perception</papertitle> <br/>
        Rajat Shinde, Abhishek Potnis, Surya Durbha <br/>
        <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020, virtual conference) </i> <br/>
      </p>  
    </td>
  </tr>

  <tr>
    <td width="20%">
      <center><img src="assets/images/nmtIgarss2020.png" style="width:90%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Towards Natural Language Question Answering Over Earth Observation Linked Data Using Attention-based Neural Machine Translation </papertitle> <br/>
    Abhishek Potnis, Rajat Shinde, Surya Durbha<br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020, virtual conference)</i> <br/>
      </p>  
    </td>
  </tr>

  <tr>
    <td width="20%">
      <center><img src="assets/images/csIgarss2019.gif" style="width:90%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Compressive Sensing Based Reconstruction And Pixel-Level Classification of VHR Disaster Satellite Imagery Using Deep Learning</papertitle> <br/>
    Rajat Shinde, Abhishek Potnis, Surya Durbha, Prakash Andugula <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</i> <br/>
    <a href="#link" onclick="$('iframe#csIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8899871">
        pdf | </a>
    <a href="#link" onclick="$('iframe#csIgarssBibtex').toggle()"> BibTeX </a><br />
    
    <iframe srcdoc="<p>Disasters such as earthquakes, floods, landslides etc. create great economic and social loss by destroying the balance of life and property and create chaos. In the wake of a disaster, it becomes very significant to take real-time and on-the-fly actions to minimize the effects of the event. Remote Sensing data acquired through airborne or spaceborne platforms is usually huge in size and requires huge time in generating actionable insights during the disaster scenario. In this work, we propose a two-fold analysis of the Very High Resolution (VHR) satellite imagery based on Compressive Sensing (CS) and Deep Learning. We propose employing a deep learning approach for inferencing over compressed sensing satellite imagery. We hypothesize that this could be beneficial in generating real-time actionable insights during a catastrophe. In our work, we are using the satellite imagery from GeoEye-1 of Haiti Earthquake. Our objectives are: (1) To generate CS images for 75%, 50%, and, 25% sampling on the sparse space and (2) To develop a deep learning pixel-level classification model based on the UNet architecture using the original and reconstructed images. The UNet architecture has shown promising results for pixel-level classification in the recent literature. We envisage to combine both the objectives into an end-to-end learning framework for on-board processing which we foresee would be of great significance in various applications for rapid disaster management response.</p>" class="abstract" id="csIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

    <iframe srcdoc="<pre>@inproceedings{shinde2019compressive,
    title={Compressive Sensing Based Reconstruction and Pixel-Level Classification of Very High-Resolution Disaster Satellite Imagery Using Deep Learning},
    author={Shinde, Rajat C and Potnis, Abhishek V and Durbha, Surya S and Andugula, Prakash},
    booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
    pages={2639--2642},
    year={2019},
    organization={IEEE}
    }</pre>" id="csIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

      </p>  
    </td>
  </tr>

  <tr>
    <td width="20%">
      <center><img src="assets/images/mlcIgarss2019.png" style="width:90%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Multi-class Segmentation of Urban Floods From Multispectral Imagery Using Deep Learning</papertitle> <br/>
    Abhishek Potnis, Rajat Shinde, Surya Durbha, Kuldeep Kurte <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</i> <br/>
    <a href="#link" onclick="$('iframe#mlIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8900250">
        pdf | </a>
    <a href="#link" onclick="$('iframe#mlIgarssBibtex').toggle()"> BibTeX </a><br />
    
    <iframe srcdoc="<p>Natural disasters such as floods, earthquakes, hurricanes, etc. have a huge impact on a society-causing destruction of life and property in their wake. During disasters such as flood, it is crucial to understand the dynamics of the situation as it occurs for effective response. In this paper, we address the problem of satellite image classification for urban floods using deep learning. We propose an encoder-decoder neural network based on the Efficient Residual Factorized Convnet(ERFNet), for multi-class segmentation of urban floods from multi-spectral satellite imagery. The ERFNet architecture capitalizes on skip connections and one dimensional convolutions to achieve the best possible trade-off between accuracy and efficiency. Since time is of essence during a disaster, the choice of the ERFNet architecture on a high performance computing (HPC) platform is apt. Satellite imagery from WorldView-2 of floods in Srinagar, India during September 2014 have been used for this study. The tool `markGT' has been developed to assist end-to-end annotation of satellite imagery. The urban flood dataset used for this study has been generated using markGT. The proposed deep learning model over urban flood satellite imagery gives promising results on Nvidia Tesla K80 GPU. We envisage that the proposed model could be extended and improved for real-time classification of urban floods, thereby aiding disaster response personnel in making informed decisions.</p>" class="abstract" id="mlIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

    <iframe srcdoc="<pre>@inproceedings{potnis2019multi,
    title={Multi-Class Segmentation of Urban Floods from Multispectral Imagery Using Deep Learning},
    author={Potnis, Abhishek V and Shinde, Rajat C and Durbha, Surya S and Kurte, Kuldeep R},
    booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
    pages={9741--9744},
    year={2019},
    organization={IEEE}
    }</pre>" id="mlIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
      </p>  
    </td>
  </tr>

  <tr>
    <td width="20%">
      <center><img src="assets/images/ubIgarss2019.png" style="width:90%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Rapid Earthquake Damage Detection Using Deep Learning From VHR Remote Sensing Images</papertitle> <br/>
    Ujwala Bhangale, Surya Durbha, Abhishek Potnis, Rajat Shinde <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan </i> <br/>
    <a href="#link" onclick="$('iframe#eqIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8898147">
        pdf | </a>
    <a href="#link" onclick="$('iframe#eqIgarssBibtex').toggle()"> BibTeX </a><br />
    
    <iframe srcdoc="<p>Very High Resolution (VHR) remote sensing optical imagery is a huge source of information that can be utilized for earthquake damage detection and assessment. Time critical task such as performing the damage assessment, providing immediate delivery of relief assistance require immediate response; however, processing voluminous VHR imagery using highly accurate, but computationally expensive deep learning algorithms demands the High Performance Computing (HPC) power. To maximize the accuracy, deep convolution neural network (CNN) model is designed especially for the earthquake damage detection using remote sensing data and implemented using high performance GPU without compromising with the execution time. Geoeye1 VHR disaster images of the Haiti earthquake occurred in year 2010 is used for analysis. Proposed model provides good accuracy for damage detection; also significant execution speed is observed on GPU K80 High Performance Computing (HPC) platform.</p>" class="abstract" id="eqIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

    <iframe srcdoc="<pre>@inproceedings{bhangale2019rapid,
    title={Rapid Earthquake Damage Detection Using Deep Learning from VHR Remote Sensing Images},
    author={Bhangale, Ujwala and Durbha, Surya and Potnis, Abhishek and Shinde, Rajat},
    booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
    pages={2654--2657},
    year={2019},
    organization={IEEE}
    }</pre>" id="eqIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
      </p>  
    </td>
  </tr>

  <tr>
    <td width="20%">
      <center><img src="assets/images/krIgarss2019.png" style="width:90%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Semantic Framework For Spatial Query Reformulation For Disaster Monitoring Applications</papertitle> <br/>
    Kuldeep Kurte, Abhishek Potnis, Surya Durbha, Rajat Shinde <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan </i> <br/>
    <a href="#link" onclick="$('iframe#sfIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8898986">
        pdf | </a>
    <a href="#link" onclick="$('iframe#sfIgarssBibtex').toggle()"> BibTeX </a><br />

    <iframe srcdoc="<p>In disasters, since time is of the essence, quick decision making based on actionable insights is desired. In our earlier work, we have demonstrated that the spatial relationships-based queries can play a vital role in the disaster response phase. However, we found that the utilization of spatial relationships rules (i.e. encoded spatial knowledge) via rule reasoning process do not scale well with the increased number of image regions. Most of the available Resource Description Framework (RDF) triplestores do not support rule reasoning due to the computational complexity and undecidable nature of the rule reasoning process. In this paper, we propose an alternative approach for utilizing spatial knowledge encoded in the form of spatial relationship rules. The proposed approach reformulates the spatial query by expanding it with the configuration encoded in the corresponding spatial relationship rule. The preliminary results are promising and show the applicability of the proposed approach during the time critical events such as flood disaster.</p>" class="abstract" id="sfIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
    
    <iframe srcdoc="<pre>@inproceedings{kurte2019semantic,
    title={Semantic Framework for Spatial Query Reformulation for Disaster Monitoring Applications},
    author={Kurte, Kuldeep R and Potnis, Abhishek V and Durbha, Surya S and Shinde, Rajat C},
    booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
    pages={9946--9949},
    year={2019},
    organization={IEEE}
    }</pre>" id="sfIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
      </p>  
    </td>
  </tr>

  <tr>
    <td width="20%">
      <center><img src="assets/images/ijert.png" style="width:90%;"></center>
    </td>
    <td width="80%" valign="middle">
      <p><papertitle>Information Table based Decision Approach for Broadcast Storm Suppression in Vehicular Ad-Hoc Networks</papertitle> <br/>
    Aditya Om, Rajat Shinde, Sejal Agrawal, A.S. Raghuvanshi <br/>
    <i>International Journal of Engineering and Technical Research V5(04), April 2016</i> <br />
    <a href="#link" onclick="$('iframe#ijertAbstract').toggle()"> Abstract |</a>
    <a href="http://dx.doi.org/10.17577/IJERTV5IS040769">
        pdf | </a>
    <a href="#link" onclick="$('iframe#ijertBibtex').toggle()"> BibTeX </a><br />

    <iframe srcdoc="<p>Various multi-hop applications in MANETs in general and VANETS in particular, use broadcasting as a method for propagating useful traffic information, paging a particular host, route discovery etc. to neighboring nodes located within a logical and geographical boundary. However broadcasting via the conventional mechanism leads to high level of network contention, and flooding at Data Link Layer which causes dropping of packets and loss of information. In VANETs, the network topology is dynamically changing and selfâ€“arranging and a minor loss of packet or end to end delay may propagate in time and evolve in a chaotic scenario in real time use case. In this paper we have presented a novel routing algorithm â€“ MARS. MARS is based on i-table approach analogous to IP-Table model as decision control mechanism in deciding the next hop node for packet forwarding. It mitigates BSP, specifically in VANET applications and scenario as we have considered the properties of VANET in our use case. A comparison of results with existing routing protocols viz. AODV and EIGRP for the defined performance metrics against that obtained with MARS in EXata Simulation environment has been shown. </p>" class="abstract" id="ijertAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
    
    <iframe srcdoc="<pre>@article{shinde2016information,
    title={Information Table based Decision Approach for Broadcast Storm Suppression in Vehicular Ad-Hoc Networks},
    author={Shinde, Rajat Chandrashekhar and Agrawal, Sejal and Om, AS Raghuvanshi Aditya},
    journal={International Journal of Engineering Research and Technology (IJERT)},
    volume={5},
    number={4},
    pages={515--520},
    year={2016}
    }</pre>" id="ijertBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
      </p>  
    </td>
  </tr>
</table>

<!-- <p>
<ul>
  <li><papertitle>Online Point Cloud Super Resolution Using Dictionary Learning For 3d Urban Perception</papertitle> <br/>
    Rajat Shinde, Abhishek Potnis, Surya Durbha <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020, virtual conference) </i> <br/>
    <a href="https://ieeexplore.ieee.org/abstract/document/8899871">
        pdf | </a>
    <a href="#link" onclick="$('iframe#csIgarss').toggle()"> BibTeX </a><br /> -->
    
    <!-- <iframe srcdoc="<pre>@inproceedings{shinde2019compressive,
  title={Compressive Sensing Based Reconstruction and Pixel-Level Classification of Very High-Resolution Disaster Satellite Imagery Using Deep Learning},
  author={Shinde, Rajat C and Potnis, Abhishek V and Durbha, Surya S and Andugula, Prakash},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={2639--2642},
  year={2019},
  organization={IEEE}
}</pre>" id="csIgarss" height="90%" width="100%" scrolling="yes" style="display:none">
</iframe>

  </li>
  <li><papertitle>Towards Natural Language Question Answering Over Earth Observation Linked Data Using Attention-based Neural Machine Translation </papertitle> <br/>
    Abhishek Potnis, Rajat Shinde, Surya Durbha<br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2020, virtual conference)</i> <br/>
     <a href="https://ieeexplore.ieee.org/abstract/document/8899871">
        pdf | </a>
    <a href="#link" onclick="$('iframe#csIgarss').toggle()"> BibTeX </a><br />
     -->
    <!-- <iframe srcdoc="<pre>@inproceedings{shinde2019compressive,
  title={Compressive Sensing Based Reconstruction and Pixel-Level Classification of Very High-Resolution Disaster Satellite Imagery Using Deep Learning},
  author={Shinde, Rajat C and Potnis, Abhishek V and Durbha, Surya S and Andugula, Prakash},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={2639--2642},
  year={2019},
  organization={IEEE}
}</pre>" id="csIgarss" height="90%" width="100%" scrolling="yes" style="display:none">
</iframe> -->

<!--  </li>
  <li><papertitle>Compressive Sensing Based Reconstruction And Pixel-Level Classification of VHR Disaster Satellite Imagery Using Deep Learning</papertitle> <br/>
    Rajat Shinde, Abhishek Potnis, Surya Durbha, Prakash Andugula <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</i> <br/>
    <a href="#link" onclick="$('iframe#csIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8899871">
        pdf | </a>
    <a href="#link" onclick="$('iframe#csIgarssBibtex').toggle()"> BibTeX </a><br />
    
    <iframe srcdoc="<p>Disasters such as earthquakes, floods, landslides etc. create great economic and social loss by destroying the balance of life and property and create chaos. In the wake of a disaster, it becomes very significant to take real-time and on-the-fly actions to minimize the effects of the event. Remote Sensing data acquired through airborne or spaceborne platforms is usually huge in size and requires huge time in generating actionable insights during the disaster scenario. In this work, we propose a two-fold analysis of the Very High Resolution (VHR) satellite imagery based on Compressive Sensing (CS) and Deep Learning. We propose employing a deep learning approach for inferencing over compressed sensing satellite imagery. We hypothesize that this could be beneficial in generating real-time actionable insights during a catastrophe. In our work, we are using the satellite imagery from GeoEye-1 of Haiti Earthquake. Our objectives are: (1) To generate CS images for 75%, 50%, and, 25% sampling on the sparse space and (2) To develop a deep learning pixel-level classification model based on the UNet architecture using the original and reconstructed images. The UNet architecture has shown promising results for pixel-level classification in the recent literature. We envisage to combine both the objectives into an end-to-end learning framework for on-board processing which we foresee would be of great significance in various applications for rapid disaster management response.</p>" class="abstract" id="csIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

    <iframe srcdoc="<pre>@inproceedings{shinde2019compressive,
  title={Compressive Sensing Based Reconstruction and Pixel-Level Classification of Very High-Resolution Disaster Satellite Imagery Using Deep Learning},
  author={Shinde, Rajat C and Potnis, Abhishek V and Durbha, Surya S and Andugula, Prakash},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={2639--2642},
  year={2019},
  organization={IEEE}
}</pre>" id="csIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

  </li>
  <li><papertitle>Multi-class Segmentation of Urban Floods From Multispectral Imagery Using Deep Learning</papertitle> <br/>
    Abhishek Potnis, Rajat Shinde, Surya Durbha, Kuldeep Kurte <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan</i> <br/>
    <a href="#link" onclick="$('iframe#mlIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8900250">
        pdf | </a>
    <a href="#link" onclick="$('iframe#mlIgarssBibtex').toggle()"> BibTeX </a><br />
    
    <iframe srcdoc="<p>Natural disasters such as floods, earthquakes, hurricanes, etc. have a huge impact on a society-causing destruction of life and property in their wake. During disasters such as flood, it is crucial to understand the dynamics of the situation as it occurs for effective response. In this paper, we address the problem of satellite image classification for urban floods using deep learning. We propose an encoder-decoder neural network based on the Efficient Residual Factorized Convnet(ERFNet), for multi-class segmentation of urban floods from multi-spectral satellite imagery. The ERFNet architecture capitalizes on skip connections and one dimensional convolutions to achieve the best possible trade-off between accuracy and efficiency. Since time is of essence during a disaster, the choice of the ERFNet architecture on a high performance computing (HPC) platform is apt. Satellite imagery from WorldView-2 of floods in Srinagar, India during September 2014 have been used for this study. The tool `markGT' has been developed to assist end-to-end annotation of satellite imagery. The urban flood dataset used for this study has been generated using markGT. The proposed deep learning model over urban flood satellite imagery gives promising results on Nvidia Tesla K80 GPU. We envisage that the proposed model could be extended and improved for real-time classification of urban floods, thereby aiding disaster response personnel in making informed decisions.</p>" class="abstract" id="mlIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

    <iframe srcdoc="<pre>@inproceedings{potnis2019multi,
  title={Multi-Class Segmentation of Urban Floods from Multispectral Imagery Using Deep Learning},
  author={Potnis, Abhishek V and Shinde, Rajat C and Durbha, Surya S and Kurte, Kuldeep R},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={9741--9744},
  year={2019},
  organization={IEEE}
}</pre>" id="mlIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
</iframe>
  </li>

  <li><papertitle>Rapid Earthquake Damage Detection Using Deep Learning From VHR Remote Sensing Images</papertitle> <br/>
    Ujwala Bhangale, Surya Durbha, Abhishek Potnis, Rajat Shinde <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan </i> <br/>
    <a href="#link" onclick="$('iframe#eqIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8898147">
        pdf | </a>
   <a href="#link" onclick="$('iframe#eqIgarssBibtex').toggle()"> BibTeX </a><br />
    
    <iframe srcdoc="<p>Very High Resolution (VHR) remote sensing optical imagery is a huge source of information that can be utilized for earthquake damage detection and assessment. Time critical task such as performing the damage assessment, providing immediate delivery of relief assistance require immediate response; however, processing voluminous VHR imagery using highly accurate, but computationally expensive deep learning algorithms demands the High Performance Computing (HPC) power. To maximize the accuracy, deep convolution neural network (CNN) model is designed especially for the earthquake damage detection using remote sensing data and implemented using high performance GPU without compromising with the execution time. Geoeye1 VHR disaster images of the Haiti earthquake occurred in year 2010 is used for analysis. Proposed model provides good accuracy for damage detection; also significant execution speed is observed on GPU K80 High Performance Computing (HPC) platform.</p>" class="abstract" id="eqIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>

    <iframe srcdoc="<pre>@inproceedings{bhangale2019rapid,
  title={Rapid Earthquake Damage Detection Using Deep Learning from VHR Remote Sensing Images},
  author={Bhangale, Ujwala and Durbha, Surya and Potnis, Abhishek and Shinde, Rajat},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={2654--2657},
  year={2019},
  organization={IEEE}
}</pre>" id="eqIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
</iframe>
  </li>

  <li><papertitle>Semantic Framework For Spatial Query Reformulation For Disaster Monitoring Applications</papertitle> <br/>
    Kuldeep Kurte, Abhishek Potnis, Surya Durbha, Rajat Shinde <br/>
    <i>IEEE International Geoscience and Remote Sensing Symposium (IGARSS 2019), Japan </i> <br/>
    <a href="#link" onclick="$('iframe#sfIgarssAbstract').toggle()"> Abstract |</a>
    <a href="https://ieeexplore.ieee.org/abstract/document/8898986">
        pdf | </a>
    <a href="#link" onclick="$('iframe#sfIgarssBibtex').toggle()"> BibTeX </a><br />

    <iframe srcdoc="<p>In disasters, since time is of the essence, quick decision making based on actionable insights is desired. In our earlier work, we have demonstrated that the spatial relationships-based queries can play a vital role in the disaster response phase. However, we found that the utilization of spatial relationships rules (i.e. encoded spatial knowledge) via rule reasoning process do not scale well with the increased number of image regions. Most of the available Resource Description Framework (RDF) triplestores do not support rule reasoning due to the computational complexity and undecidable nature of the rule reasoning process. In this paper, we propose an alternative approach for utilizing spatial knowledge encoded in the form of spatial relationship rules. The proposed approach reformulates the spatial query by expanding it with the configuration encoded in the corresponding spatial relationship rule. The preliminary results are promising and show the applicability of the proposed approach during the time critical events such as flood disaster.</p>" class="abstract" id="sfIgarssAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
    
    <iframe srcdoc="<pre>@inproceedings{kurte2019semantic,
  title={Semantic Framework for Spatial Query Reformulation for Disaster Monitoring Applications},
  author={Kurte, Kuldeep R and Potnis, Abhishek V and Durbha, Surya S and Shinde, Rajat C},
  booktitle={IGARSS 2019-2019 IEEE International Geoscience and Remote Sensing Symposium},
  pages={9946--9949},
  year={2019},
  organization={IEEE}
}</pre>" id="sfIgarssBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
</iframe>
  </li>

  <li><papertitle>Information Table based Decision Approach for Broadcast Storm Suppression in Vehicular Ad-Hoc Networks</papertitle> <br/>
    Aditya Om, Rajat Shinde, Sejal Agrawal, A.S. Raghuvanshi <br/>
    <i>International Journal of Engineering and Technical Research V5(04), April 2016</i> <br />
    <a href="#link" onclick="$('iframe#ijertAbstract').toggle()"> Abstract |</a>
    <a href="http://dx.doi.org/10.17577/IJERTV5IS040769">
        pdf | </a>
    <a href="#link" onclick="$('iframe#ijertBibtex').toggle()"> BibTeX </a><br />

    <iframe srcdoc="<p>Various multi-hop applications in MANETs in general and VANETS in particular, use broadcasting as a method for propagating useful traffic information, paging a particular host, route discovery etc. to neighboring nodes located within a logical and geographical boundary. However broadcasting via the conventional mechanism leads to high level of network contention, and flooding at Data Link Layer which causes dropping of packets and loss of information. In VANETs, the network topology is dynamically changing and selfâ€“arranging and a minor loss of packet or end to end delay may propagate in time and evolve in a chaotic scenario in real time use case. In this paper we have presented a novel routing algorithm â€“ MARS. MARS is based on i-table approach analogous to IP-Table model as decision control mechanism in deciding the next hop node for packet forwarding. It mitigates BSP, specifically in VANET applications and scenario as we have considered the properties of VANET in our use case. A comparison of results with existing routing protocols viz. AODV and EIGRP for the defined performance metrics against that obtained with MARS in EXata Simulation environment has been shown. </p>" class="abstract" id="ijertAbstract" height="90%" width="100%" scrolling="yes" style="display:none">
    </iframe>
    
    <iframe srcdoc="<pre>@article{shinde2016information,
  title={Information Table based Decision Approach for Broadcast Storm Suppression in Vehicular Ad-Hoc Networks},
  author={Shinde, Rajat Chandrashekhar and Agrawal, Sejal and Om, AS Raghuvanshi Aditya},
  journal={International Journal of Engineering Research and Technology (IJERT)},
  volume={5},
  number={4},
  pages={515--520},
  year={2016}
  }</pre>" id="ijertBibtex" height="90%" width="100%" scrolling="yes" style="display:none">
  </iframe>
  </li> 

</ul>
</p> -->

<!--<heading>Projects</heading>
<p>
<ul>
  <li> 
    <b>Google Summer of Earth Engine 2019 </b><br/>
    Student developer for <a href="https://www.ncf-india.org/"> Nature Conservation Foundation</a> under the mentorship of Dr. M D Madhusudan
      <ul><li>Developed <b>EcoViz: A Google Earth Engine based web application for robust visualization of ecological status of selected world heritage sites of the Western Ghats in India </b></li></ul>

    <p>
    <a href="https://rajatshinde2303.users.earthengine.app/view/ecoviz"> App |</a>
    <a href="https://docs.google.com/presentation/d/16WEnUgjZVqxWb4sF3HNTpyZpTTsBjNwq78UNgKM0qg4/edit?usp=sharing"> Presentation</a>
    </p>
  </li>

<li>
<b>Earth Engine India Advanced Summit Buildathon 2019 </b> <br/>
    Worked on "Locating Solar Farms in Selected Sites of India using Google Earth Engine"
    <ul>
      <li>In a team of 6, implemented random-forest classifier to solve binary classification problem (Solar Farm: 1, Non-Solar farm: 0) with an accuracy of 81% </li>
      <li>Added Wavelet Kernel-based convolution approach for solar panels texture detection thus improving the accuracy to 83.6% 
      </li>
    </ul>


    <p>
    <a href="https://docs.google.com/presentation/d/1rVrLnrl9H-aglIA4UEr7Ajn249WBWNN2wKxDW25h-MQ/edit"> Presentation |</a>
    <a href="https://code.earthengine.google.com/b4f563c2bf05f0a5992a68273e7c4ae0"> Code |</a>
    <a href="https://sites.google.com/view/eeindia-advanced-summit/summit-resources#h.p_xf20uslDUytp"> Buildathon </a>
    </p>

</li>
<li>
<b>Earthquake Prediction Using Machine Learning Techniques </b>
    <ul>
      <li>In a team of 4, implemented machine learning models(SVM, ANN, Random Forests & Decision Tree Classifier) obtaining maximum accuracy of 94.5% to predict the earthquake in the Andaman & Nicobar Islands and Sumatra region</li>
      <li>Extracted features (b-values) from USGS earthquake dataset of the last 26 years to train models</li>
    </ul>
 
    <p>
    <a href="https://drive.google.com/open?id=1W0IG_96HVdL6pO5Tj1CfjboI1nxA2Lsw"> Report</a>
    </p>

</li>
<li>
<b>Image Pre-processing using Lee & Gradient-Inverse Kernels </b>
    <ul>
      <li>Implemented Lee kernel and Gradient-Inverse kernel for satellite image pre-processing </li>
      <li>Developed a Graphical User Interface (GUI) based application in MATLAB</li>
    </ul>

    <p>
    <a href="https://github.com/omshinde/Lee-GradInv-filters#lee-gradinv-filters"> Report |</a>
    <a href="https://github.com/omshinde/Lee-GradInv-filters"> Code</a>
    </p>
</li>
</ul>
</p>
 
<heading>Open Source Contributions</heading>
<p><ul>
  <li>

    <b>Google Summer of Code 2019 </b>Mentor for <a href="http://mapmint.com/"> MapMint</a> under <a href="https://summerofcode.withgoogle.com/archive/2017/organizations/4554340639440896/">OSGeo</a> organization 
    <ul>
        <li>Adding Augmented Reality (AR) support to the MapMint4ME Android Application

          <p>
          <a href="https://summerofcode.withgoogle.com/archive/2019/projects/5962182162907136/"> Project |</a>
          <a href="https://github.com/AdityaChondke/MapMint4ME/wiki/Final-Report-GSoC-2019"> Report </a>
          </p>
        </li>

        <li>MapMint - porting from Python 2.x to Python 3.x

        <p>
        <a href="https://summerofcode.withgoogle.com/archive/2019/projects/4859857885200384/"> Project |</a>
        <a href="https://github.com/fenilgmehta/mapmint/wiki/GSoC-2019---Final-Report"> Report </a>
        </p>
        </li>
    </ul>
  </li><br/>
  <li><a href="https://www.osgeo.org/">OSGeo </a> India - <a href="https://www.osgeo.org/about/charter-members/">Charter Member </a></li><br/>

  <li>
    <b>Google Summer of Code 2018 </b>Mentor for <a href="http://mapmint.com/"> MapMint</a> under <a href="https://summerofcode.withgoogle.com/archive/2018/organizations/4890968767594496/">OSGeo</a> organization
  </li><br/>

  <li>
    <b>Google Summer of Code 2017 </b>Student for <a href="http://mapmint.com/">MapMint </a>under <a href="https://summerofcode.withgoogle.com/archive/2017/organizations/4554340639440896/">OSGeo </a>organization
    <ul>
      <li>Added Audio and Video data recording capability to the <a href="https://play.google.com/store/apps/details?id=fr.geolabs.dev.mapmint4me&hl=en_GB">MapMint4ME </a> Android application
      </li>
      <li>Added Sensor data recording capability to the MapMint4ME Android application for remote data acquisition
      </li>
    </ul>


    <p>
    <a href="https://summerofcode.withgoogle.com/archive/2017/projects/5784917489221632/"> Project |</a>
    <a href="https://wiki.osgeo.org/wiki/GSoC_17:_Add_Audio,_Video_and_SOS_input_support_in_MapMint4ME"> Wiki </a>
    <a href="{{site.baseurl}}/assets/docs/gsocCertificate2017.pdf"> | Certificate of Completion </a>
    </p>
  </li>
</ul></p> 

<heading>Awards</heading>

  <ul>
    <li><a href="https://sites.google.com/earthoutreach.org/eeindiachallenge/home">Google Earth Engine India Challenge 2018</a> <br/>
    One of the 7 <a href="https://sites.google.com/earthoutreach.org/eeindiachallenge/winners">Winners</a> of contest for Indian university students interested in geospatial data analysis
    </li>

    <li><a href="https://innovate.mygov.in/india-innovation-challenge-design-contest-2017/">DST & Texas Instruments India Innovation Challenge Design Contest 2017 </a><br/>
    Quarter Finalists for the Innovation Challenge anchored by IIM, Bangalore | <a href="https://drive.google.com/file/d/1yoJd7kPHHDMmLKik_YqeU4gIEYzWPXA4/view">Certificate </a>
    </li>
  </ul> -->
</div>

<div>
<heading id="courses">Courses</heading>
  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="5px">
    <tr>
      <td width="50%" valign="middle">
        <ul>
          <li><b>GNR 603</b> - Principles of Remote Sensing</li>
          <li><b>GNR 605</b> - Principles of Geographic Information Systems</li>
          <li><b>GNR 607</b> - Principles of Satellite Image Processing</li>
          <li><b>GNR 615</b> - GIS Laboratory</li>
          <li><b>GNR 617</b> - Image Interpretation Laboratory</li>
          <li><b>GNR 619</b> - Natural Resources : Lithosphere and Biosphere</li>
          <li><b>GNR 621</b> - Natural Resources: Hydroshpere, Cryosphere and Atmosphere</li>
          <li><b>CS 725</b> - Foundations of Machine Learning</li>
        </ul>
      </td>
      <td width="50%" valign="middle">
        <ul>
          <li><b>GNR 602</b> - Advanced Methods in Satellite Image Processing</li>
          <li><b>GNR 633</b> - Remote Sensing and GIS Applications to Mineral and Hydrocarbon Exploration</li>
          <li><b>GNR 694</b> - Seminar</li>
          <li><b>GNR 792</b> - Communication Skills -II</li>
          <li><b>HS 791</b> - Communication Skills -I</li>
          <li><b>GNR 627</b> - Geospatial Predictive Modelling</li>
          <li><b>GNR 629</b> - Advances in Geospatial Standards, Interoperability and Knowledge Discovery</li>
        </ul>
      </td>
      <!--<td>
        <ul>
          <li><b>GNR 615</b> - Principles of Geographic Information Systems Lab 2018 Autumn</li>
          <li><b>GNR 615</b> - Principles of Geographic Information Systems Lab 2017 Autumn</li>
          <li><b>GNR 603</b> - Satellite Image Processing 2017 Autumn</li>
          <li><b>GNR 402</b> - Introduction to Geographic Information Systems 2017 Autumn</li>
        </ul>
      </td>-->
    </tr>
  </table>
</div>

<div>
<heading id="ta">Teaching Assistantship</heading>
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="5px">
    <tr>
      <td width="50%" valign="middle">
        <ul>
          <li><b>GNR 615</b> - Principles of Geographic Information Systems Lab 2018 Autumn</li>
          <li><b>GNR 615</b> - Principles of Geographic Information Systems Lab 2017 Autumn</li>
          <li><b>GNR 603</b> - Satellite Image Processing 2017 Autumn</li>
          <li><b>GNR 402</b> - Introduction to Geographic Information Systems 2017 Autumn</li>
        </ul>
      </td>
    </tr>
</table>
<!-- <p>
  <ul>
    <li><b>GNR 615</b> - Principles of Geographic Information Systems Lab 2018 Autumn</li>
    <li><b>GNR 615</b> - Principles of Geographic Information Systems Lab 2017 Autumn</li>
    <li><b>GNR 603</b> - Satellite Image Processing 2017 Autumn</li>
    <li><b>GNR 402</b> - Introduction to Geographic Information Systems 2017 Autumn</li>
  </ul>
</p> -->
</div>
      
<div> 
<hr>
<p>
  <i>
    Last Edited: November 03, 2020 20:03
  </i>
</p>
</div>
</div>
</body>
</head>
</html>